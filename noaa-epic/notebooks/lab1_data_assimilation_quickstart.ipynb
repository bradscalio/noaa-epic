{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1 \u2014 Data Assimilation Quickstart (CADRE on OpenShift)\n",
        "Goal: run a small 3DVAR cycle on sample NOAA data inside an RHODS Workbench, then hand off to Tekton for a full pipeline run.\n",
        "## Steps\n",
        "1. Verify GPU and storage\n",
        "2. Pull sample dataset from `/data/raw` or S3 bucket\n",
        "3. Run pre-processing\n",
        "4. Execute a toy DA step (mock JEDI/DART)\n",
        "5. Persist artifacts to `/data/experiments/lab1`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, json, subprocess, pathlib\n",
        "from datetime import datetime\n",
        "base = pathlib.Path('/data/experiments/lab1')\n",
        "base.mkdir(parents=True, exist_ok=True)\n",
        "print('GPU visible:', os.environ.get('NVIDIA_VISIBLE_DEVICES','auto'))\n",
        "print('Workspace:', base)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess (placeholder)\n",
        "Replace with your real preproc. Writes to `/data/experiments/lab1/preproc`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pre = base/'preproc'\n",
        "pre.mkdir(exist_ok=True)\n",
        "with open(pre/'index.txt','w') as f:\n",
        "    f.write('placeholder preproc outputs\\n')\n",
        "print('Preproc complete')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run a mock DA step\n",
        "This simulates calling a containerized DA binary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "da = base/'da'\n",
        "da.mkdir(exist_ok=True)\n",
        "with open(da/'analysis.nc','w') as f:\n",
        "    f.write('mock netcdf bytes')\n",
        "print('DA step complete')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trigger Tekton pipeline (optional)\n",
        "Requires the `oc` CLI in the workbench image and appropriate RBAC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import subprocess\n",
        "start_date='2025-07-01'\n",
        "end_date='2025-07-07'\n",
        "scheme='3dvar'\n",
        "cmd=['oc','-n','cadre-labs','create','-f','-']\n",
        "pipelinerun=f'''apiVersion: tekton.dev/v1\n",
        "kind: PipelineRun\n",
        "metadata:\\n  generateName: cadre-lab1-run-\\nspec:\\n  pipelineRef:\\n    name: cadre-train\\n  params:\\n  - name: start_date\\n    value: {start_date}\\n  - name: end_date\\n    value: {end_date}\\n  - name: scheme\\n    value: {scheme}\\n  workspaces:\\n  - name: shared-ws\\n    volumeClaimTemplate:\\n      spec:\\n        accessModes: [\"ReadWriteOnce\"]\\n        resources:\\n          requests:\\n            storage: 20Gi\\n'''\n",
        "print(pipelinerun)\n",
        "# subprocess.run(cmd, input=pipelinerun.encode(), check=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}